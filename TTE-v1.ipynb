{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12b26f5-8776-4c4a-a876-7726e1797e34",
   "metadata": {},
   "source": [
    "# **Target Trial Emulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a6341-9736-4412-8c58-eb38f9e41d08",
   "metadata": {},
   "source": [
    "### **Submitted by:**\n",
    "- **Ladrera**, Raiken\n",
    "- **Tibon**, Hestia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995110c-b937-411b-a74b-e549b35d8fc7",
   "metadata": {},
   "source": [
    "## **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8195ac-f9a9-4240-92a8-c3e7face5e4f",
   "metadata": {},
   "source": [
    "Assignment 1 for Clustering: New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "- Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "- Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "- Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "- Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "- Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "- Do this by pair, preferably your thesis partner.\n",
    "- Push to your github repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52acd26-f363-4cbb-9f2b-ee78ed563c0e",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e6bb922-7be2-4b1e-bf7d-6298a0b94219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP directory: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_pp\n",
      "ITT directory: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_itt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "print(f\"PP directory: {trial_pp_dir}\")\n",
    "print(f\"ITT directory: {trial_itt_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ddcb3-eb59-4048-a15f-c94650a8635e",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eeeac09d-9941-4219-af83-9d47898c3d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Preview:\n",
      "\n",
      "Prepared data (PP Model):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "\n",
      "Prepared data (ITT Model):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n"
     ]
    }
   ],
   "source": [
    "data_censored = pd.read_csv('data_censored.csv')\n",
    "\n",
    "print(\"Initial Data Preview:\")\n",
    "#print(data_censored.head())\n",
    "\n",
    "def set_data(data, id_col, period, treatment, outcome, eligible):\n",
    "    df = dict()\n",
    "    df['data'] = data.copy()\n",
    "    df['id'] = id_col\n",
    "    df['period'] = period\n",
    "    df['treatment'] = treatment\n",
    "    df['outcome'] = outcome\n",
    "    df['eligible'] = eligible\n",
    "\n",
    "    return df\n",
    "\n",
    "trial_pp = set_data(data=data_censored, id_col=\"id\", period=\"period\",\n",
    "                    treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\")\n",
    "trial_itt = set_data(data=data_censored, id_col=\"id\", period=\"period\",\n",
    "                     treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\")\n",
    "\n",
    "print(\"\\nPrepared data (PP Model):\")\n",
    "print(trial_pp['data'].head())\n",
    "print(\"\\nPrepared data (ITT Model):\")\n",
    "print(trial_itt['data'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63db407-de57-453e-9059-5a20504b6efc",
   "metadata": {},
   "source": [
    "## **3. Weight Models and Censoring**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fb94b-141e-4b36-949f-5da96f54bebb",
   "metadata": {},
   "source": [
    "#### **3.1. Trial Class: Treatment and Censoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8932121-1a30-43cc-9cad-9777f9487f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows with switch weights (PP):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  switch_weight  \n",
      "0         0         1       0.930088  \n",
      "1         0         0       0.928634  \n",
      "2         0         0       1.039459  \n",
      "3         0         0       1.040816  \n",
      "4         0         0       0.924292  \n"
     ]
    }
   ],
   "source": [
    "def fit_logistic_model(X, y):\n",
    "    \"\"\"\n",
    "    Fit a logistic regression model using statsmodels.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "    return model\n",
    "\n",
    "def predict_prob(model, X):\n",
    "    \"\"\"\n",
    "    Predict probabilities from a logistic regression model.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)\n",
    "    return model.predict(X)\n",
    "\n",
    "def set_switch_weight_model(data, numerator, denominator, model_fitter=fit_logistic_model, save_path=None):\n",
    "    \"\"\"\n",
    "    Fit the switch weight model for treatment switching.\n",
    "    \"\"\"\n",
    "    # Parse formulas\n",
    "    num_formula = numerator.replace(\"~\", \"\").strip()\n",
    "    num_vars = [v.strip() for v in num_formula.split(\"+\")]\n",
    "\n",
    "    den_formula = denominator.replace(\"~\", \"\").strip()\n",
    "    den_vars = [v.strip() for v in den_formula.split(\"+\")]\n",
    "\n",
    "    # Fit numerator model: treatment ~ (numerator variables)\n",
    "    X_num = data[num_vars]\n",
    "    y_treatment = data[\"treatment\"]\n",
    "    num_model = model_fitter(X_num, y_treatment)\n",
    "\n",
    "    # Fit denominator model: treatment ~ (denominator variables)\n",
    "    X_den = data[den_vars]\n",
    "    den_model = model_fitter(X_den, y_treatment)\n",
    "\n",
    "    p_num = predict_prob(num_model, X_num)\n",
    "    p_den = predict_prob(den_model, X_den)\n",
    "\n",
    "    data = data.copy()\n",
    "    data[\"switch_weight\"] = p_num / p_den\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        with open(os.path.join(save_path, \"switch_model_num.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(num_model, f)\n",
    "        with open(os.path.join(save_path, \"switch_model_den.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(den_model, f)\n",
    "\n",
    "    return {\"data\": data, \"numerator_model\": num_model, \"denominator_model\": den_model,\n",
    "            \"switch_weights\": data[\"switch_weight\"]}\n",
    "\n",
    "switch_results = set_switch_weight_model(\n",
    "    data=trial_pp['data'],\n",
    "    numerator=\"~ age\",\n",
    "    denominator=\"~ age + x1 + x3\",\n",
    "    model_fitter=fit_logistic_model,\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "trial_pp['data'] = switch_results[\"data\"]\n",
    "\n",
    "print(\"\\nFirst few rows with switch weights (PP):\")\n",
    "print(trial_pp['data'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fead91-70df-4fe9-815e-7e33cded660c",
   "metadata": {},
   "source": [
    "### **3.2 Other Informative Censoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c3bd031-b894-44a8-8ac0-1583d66ad84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved at: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_pp\\switch_models\\switch_model_num.pkl and C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_pp\\switch_models\\switch_model_den.pkl\n",
      "\n",
      "First few rows with censor weights (PP):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  switch_weight  not_censored  censor_weight  \n",
      "0         0         1       0.930088             1       0.955481  \n",
      "1         0         0       0.928634             1       0.970647  \n",
      "2         0         0       1.039459             1       1.016972  \n",
      "3         0         0       1.040816             1       1.021899  \n",
      "4         0         0       0.924292             1       0.968208  \n",
      "Models saved at: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_itt\\switch_models\\switch_model_num.pkl and C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_itt\\switch_models\\switch_model_den.pkl\n",
      "\n",
      "First few rows with censor weights (ITT):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  not_censored  censor_weight  \n",
      "0         0         1             1       0.955481  \n",
      "1         0         0             1       0.970647  \n",
      "2         0         0             1       1.016972  \n",
      "3         0         0             1       1.021899  \n",
      "4         0         0             1       0.968208  \n"
     ]
    }
   ],
   "source": [
    "def set_censor_weight_model(data, censor_event, numerator, denominator, pool_models=\"none\",\n",
    "                            model_fitter=fit_logistic_model, save_path=None):\n",
    "   \n",
    "    data = data.copy()\n",
    "    data[\"not_censored\"] = 1 - data[censor_event]\n",
    "\n",
    "    # Parse numerator formula\n",
    "    num_formula = numerator.replace(\"~\", \"\").strip()\n",
    "    num_vars = [v.strip() for v in num_formula.split(\"+\")]\n",
    "    # Parse denominator formula\n",
    "    den_formula = denominator.replace(\"~\", \"\").strip()\n",
    "    den_vars = [v.strip() for v in den_formula.split(\"+\")]\n",
    "\n",
    "    X_num = data[num_vars]\n",
    "    y_nc = data[\"not_censored\"]\n",
    "    num_model = model_fitter(X_num, y_nc)\n",
    "\n",
    "    # Fit denominator model: not_censored ~ x2 + x1\n",
    "    X_den = data[den_vars]\n",
    "    den_model = model_fitter(X_den, y_nc)\n",
    "\n",
    "    p_num = predict_prob(num_model, X_num)\n",
    "    p_den = predict_prob(den_model, X_den)\n",
    "\n",
    "    data[\"censor_weight\"] = p_num / p_den\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        num_path = os.path.join(save_path, \"switch_model_num.pkl\")\n",
    "        den_path = os.path.join(save_path, \"switch_model_den.pkl\")\n",
    "        with open(num_path, \"wb\") as f:\n",
    "            pickle.dump(num_model, f)\n",
    "        with open(den_path, \"wb\") as f:\n",
    "            pickle.dump(den_model, f)\n",
    "        print(f\"Models saved at: {num_path} and {den_path}\")\n",
    "\n",
    "    return {\"data\": data, \"numerator_model\": num_model, \"denominator_model\": den_model,\n",
    "            \"censor_weights\": data[\"censor_weight\"]}\n",
    "\n",
    "censor_results_pp = set_censor_weight_model(\n",
    "    data=trial_pp['data'],\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"~ x2\",\n",
    "    denominator=\"~ x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=fit_logistic_model,\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "trial_pp['data'] = censor_results_pp[\"data\"]\n",
    "print(\"\\nFirst few rows with censor weights (PP):\")\n",
    "print(trial_pp['data'].head())\n",
    "\n",
    "censor_results_itt = set_censor_weight_model(\n",
    "    data=trial_itt['data'],\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"~ x2\",\n",
    "    denominator=\"~ x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    model_fitter=fit_logistic_model,\n",
    "    save_path=os.path.join(trial_itt_dir, \"switch_models\")\n",
    ")\n",
    "trial_itt['data'] = censor_results_itt[\"data\"]\n",
    "print(\"\\nFirst few rows with censor weights (ITT):\")\n",
    "print(trial_itt['data'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a67aa0-689a-469d-83d1-61093dbd4d9d",
   "metadata": {},
   "source": [
    "## **4. Calculate Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "336e4cc4-b82e-4472-8093-cf4bd9f8dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows with overall PP weights:\n",
      "   id  PP_weight\n",
      "0   1   0.888682\n",
      "1   1   0.901376\n",
      "2   1   1.057101\n",
      "3   1   1.063608\n",
      "4   1   0.894907\n",
      "\n",
      "First few rows with ITT weights:\n",
      "   id  ITT_weight\n",
      "0   1    0.955481\n",
      "1   1    0.970647\n",
      "2   1    1.016972\n",
      "3   1    1.021899\n",
      "4   1    0.968208\n"
     ]
    }
   ],
   "source": [
    "# PP | overall weight is the product of switch and censor weights.\n",
    "trial_pp['data'][\"PP_weight\"] = trial_pp['data'][\"switch_weight\"] * trial_pp['data'][\"censor_weight\"]\n",
    "\n",
    "# ITT | Weight is simply the censor weight.\n",
    "trial_itt['data'][\"ITT_weight\"] = trial_itt['data'][\"censor_weight\"]\n",
    "\n",
    "print(\"\\nFirst few rows with overall PP weights:\")\n",
    "print(trial_pp['data'][[\"id\", \"PP_weight\"]].head())\n",
    "print(\"\\nFirst few rows with ITT weights:\")\n",
    "print(trial_itt['data'][[\"id\", \"ITT_weight\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "57aa31f7-fe70-4bae-a449-885e09e0b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s',\n",
      "       'outcome', 'censored', 'eligible', 'trial_period', 'followup_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16df47d-88b4-401d-bf53-4f9286ff2016",
   "metadata": {},
   "source": [
    "## **5. Specify Outcome Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3fb1a682-de82-4114-a67e-04ffbca01616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_outcome_model(data, adjustment_terms=None):\n",
    "    \"\"\"\n",
    "    Returns: Data with an added column named 'adjustment_terms'.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data[\"adjustment_terms\"] = adjustment_terms if adjustment_terms is not None else \"\"\n",
    "    return data\n",
    "\n",
    "trial_pp['data'] = set_outcome_model(trial_pp['data'])\n",
    "trial_itt['data'] = set_outcome_model(trial_itt['data'], adjustment_terms=\"x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a9353-bb76-47ec-ab91-866bb4a361e2",
   "metadata": {},
   "source": [
    "## **6.Expand Trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f30955b5-159d-42ab-b7a2-740c52af1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of Expanded Per-protocol data (PP):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "2   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "3   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "4   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "\n",
      "   censored  eligible  switch_weight  not_censored  censor_weight  PP_weight  \\\n",
      "0         0         1       0.930088             1       0.955481   0.888682   \n",
      "1         0         1       0.930088             1       0.955481   0.888682   \n",
      "2         0         1       0.930088             1       0.955481   0.888682   \n",
      "3         0         1       0.930088             1       0.955481   0.888682   \n",
      "4         0         1       0.930088             1       0.955481   0.888682   \n",
      "\n",
      "  adjustment_terms  trial_period  followup_time  \n",
      "0                              0              0  \n",
      "1                              1              1  \n",
      "2                              2              2  \n",
      "3                              3              3  \n",
      "4                              4              4  \n",
      "\n",
      "First few rows of Expanded Intention-to-Treat data (ITT):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "2   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "3   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "4   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "\n",
      "   censored  eligible  not_censored  censor_weight  ITT_weight  \\\n",
      "0         0         1             1       0.955481    0.955481   \n",
      "1         0         1             1       0.955481    0.955481   \n",
      "2         0         1             1       0.955481    0.955481   \n",
      "3         0         1             1       0.955481    0.955481   \n",
      "4         0         1             1       0.955481    0.955481   \n",
      "\n",
      "  adjustment_terms  trial_period  followup_time  \n",
      "0               x2             0              0  \n",
      "1               x2             1              1  \n",
      "2               x2             2              2  \n",
      "3               x2             3              3  \n",
      "4               x2             4              4  \n"
     ]
    }
   ],
   "source": [
    "def expand_trials(data, chunk_size=500, first_period=0, last_period=None):\n",
    "    \"\"\"\n",
    "    Returns: Expanded data with new columns named 'trial_period' and 'followup_time'\n",
    "    \"\"\"\n",
    "    if last_period is None:\n",
    "        last_period = first_period + 7  # e.g., 0 to 7\n",
    "\n",
    "    expanded_list = []\n",
    "    for pid, group in data.groupby(\"id\"):\n",
    "        baseline = group.iloc[0].to_dict()\n",
    "        for trial_period in range(first_period, last_period + 1):\n",
    "            row = baseline.copy()\n",
    "            row[\"trial_period\"] = trial_period\n",
    "            row[\"followup_time\"] = trial_period\n",
    "            expanded_list.append(row)\n",
    "    return pd.DataFrame(expanded_list)\n",
    "\n",
    "trial_pp_expanded = expand_trials(trial_pp['data'], chunk_size=500)\n",
    "trial_itt_expanded = expand_trials(trial_itt['data'], chunk_size=500)\n",
    "\n",
    "print(\"\\nFirst few rows of Expanded Per-protocol data (PP):\")\n",
    "print(trial_pp_expanded.head())\n",
    "print(\"\\nFirst few rows of Expanded Intention-to-Treat data (ITT):\")\n",
    "print(trial_itt_expanded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9914f-86cc-4502-bae2-a68ea0d9e889",
   "metadata": {},
   "source": [
    "## **7.Load Sample from Expanded Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a9491ed1-19b3-4705-8866-22187939b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of ITT expanded observations after sampling: 364\n"
     ]
    }
   ],
   "source": [
    "def load_expanded_data(data, seed=1234, p_control=0.5):\n",
    "    np.random.seed(seed)\n",
    "    events = data[data[\"outcome\"] == 1]\n",
    "    non_events = data[data[\"outcome\"] == 0].sample(frac=p_control, random_state=seed)\n",
    "    return pd.concat([events, non_events], ignore_index=True)\n",
    "\n",
    "trial_itt_loaded = load_expanded_data(trial_itt_expanded, seed=1234, p_control=0.5)\n",
    "print(\"\\nNumber of ITT expanded observations after sampling:\", trial_itt_loaded.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec44671-63bc-415f-851e-074f18965439",
   "metadata": {},
   "source": [
    "## **8.Fit Marginal Structural Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "80020aaf-00b8-4778-95ce-f91794e5deea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSM Results for Per-Protocol (PP) Analysis:\n",
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   R-squared:                       0.027\n",
      "Model:                            WLS   Adj. R-squared:                  0.022\n",
      "Method:                 Least Squares   F-statistic:                     4.959\n",
      "Date:                Sun, 09 Mar 2025   Prob (F-statistic):           0.000601\n",
      "Time:                        20:36:27   Log-Likelihood:                 370.05\n",
      "No. Observations:                 712   AIC:                            -730.1\n",
      "Df Residuals:                     707   BIC:                            -707.3\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0047      0.010      0.466      0.641      -0.015       0.024\n",
      "treatment      0.0394      0.011      3.581      0.000       0.018       0.061\n",
      "x1             0.0018      0.011      0.157      0.875      -0.021       0.024\n",
      "x2             0.0138      0.006      2.275      0.023       0.002       0.026\n",
      "x3            -0.0079      0.011     -0.732      0.464      -0.029       0.013\n",
      "==============================================================================\n",
      "Omnibus:                      851.764   Durbin-Watson:                   0.247\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            46875.532\n",
      "Skew:                           6.204   Prob(JB):                         0.00\n",
      "Kurtosis:                      40.764   Cond. No.                         3.42\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "MSM Results for Intention-to-Treat (ITT) Analysis:\n",
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   R-squared:                       0.060\n",
      "Model:                            WLS   Adj. R-squared:                  0.049\n",
      "Method:                 Least Squares   F-statistic:                     5.700\n",
      "Date:                Sun, 09 Mar 2025   Prob (F-statistic):           0.000186\n",
      "Time:                        20:36:27   Log-Likelihood:                 75.624\n",
      "No. Observations:                 364   AIC:                            -141.2\n",
      "Df Residuals:                     359   BIC:                            -121.8\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0095      0.019      0.488      0.626      -0.029       0.048\n",
      "treatment      0.0799      0.021      3.779      0.000       0.038       0.121\n",
      "x1             0.0018      0.022      0.083      0.934      -0.041       0.045\n",
      "x2             0.0317      0.012      2.721      0.007       0.009       0.055\n",
      "x3            -0.0174      0.021     -0.831      0.406      -0.059       0.024\n",
      "==============================================================================\n",
      "Omnibus:                      327.220   Durbin-Watson:                   0.168\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4746.604\n",
      "Skew:                           4.054   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.724   Cond. No.                         3.50\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def fit_marginal_structural_model(data, outcome, treatment, weights, covariates=None):\n",
    "    \"\"\"\n",
    "    Fit a Marginal Structural Model (MSM) using weighted regression.\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): The dataset containing the relevant variables.\n",
    "        outcome (str): The column name for the outcome variable.\n",
    "        treatment (str): The column name for the treatment variable.\n",
    "        weights (str): The column name for the weights to be used in regression.\n",
    "        covariates (list, optional): List of additional covariates to adjust for.\n",
    "    \n",
    "    Returns:\n",
    "        model (statsmodels object): The fitted regression model.\n",
    "    \"\"\"\n",
    "    X = data[[treatment] + (covariates if covariates else [])]\n",
    "    X = sm.add_constant(X)\n",
    "    y = data[outcome]\n",
    "    w = data[weights]\n",
    "    \n",
    "    model = sm.WLS(y, X, weights=w).fit()\n",
    "    return model\n",
    "\n",
    "# Fit MSM for Per-Protocol (PP) analysis\n",
    "msm_pp = fit_marginal_structural_model(\n",
    "    data=trial_pp_expanded,\n",
    "    outcome=\"outcome\",\n",
    "    treatment=\"treatment\",\n",
    "    weights=\"PP_weight\",\n",
    "    covariates=[\"x1\", \"x2\", \"x3\"]  # Add covariates if needed\n",
    ")\n",
    "\n",
    "print(\"\\nMSM Results for Per-Protocol (PP) Analysis:\")\n",
    "print(msm_pp.summary())\n",
    "\n",
    "# Fit MSM for Intention-to-Treat (ITT) analysis\n",
    "msm_itt = fit_marginal_structural_model(\n",
    "    data=trial_itt_loaded,\n",
    "    outcome=\"outcome\",\n",
    "    treatment=\"treatment\",\n",
    "    weights=\"ITT_weight\",\n",
    "    covariates=[\"x1\", \"x2\", \"x3\"]\n",
    ")\n",
    "\n",
    "print(\"\\nMSM Results for Intention-to-Treat (ITT) Analysis:\")\n",
    "print(msm_itt.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e442a9-d225-4dce-9df1-a226e6e8020b",
   "metadata": {},
   "source": [
    "**Censored:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e6db65-c6cd-427a-a91d-79552042ecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.267425\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      722\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.04069\n",
      "Time:                        17:59:53   Log-Likelihood:                -193.88\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002679\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.2059      0.165    -13.339      0.000      -2.530      -1.882\n",
      "x1            -0.7019      0.307     -2.285      0.022      -1.304      -0.100\n",
      "x2             0.4706      0.137      3.423      0.001       0.201       0.740\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "X_censor = df[[\"x1\", \"x2\"]]\n",
    "X_censor = sm.add_constant(X_censor)\n",
    "\n",
    "y_censor = df[\"censored\"]\n",
    "\n",
    "model_censor = sm.Logit(y_censor, X_censor).fit()\n",
    "\n",
    "df[\"p_censor\"] = model_censor.predict(X_censor)\n",
    "df[\"weight_censor\"] = 1 / df[\"p_censor\"]\n",
    "\n",
    "print(model_censor.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5b9a5-d862-4ef9-ba4b-47e54142f774",
   "metadata": {},
   "source": [
    "**Treatment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbffcd61-ff78-4501-91da-189dd2ae35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682194\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      721\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.01281\n",
      "Time:                        17:59:55   Log-Likelihood:                -494.59\n",
      "converged:                       True   LL-Null:                       -501.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.005012\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.2294      0.124     -1.850      0.064      -0.472       0.014\n",
      "x1             0.1908      0.153      1.246      0.213      -0.109       0.491\n",
      "x2             0.2444      0.077      3.178      0.001       0.094       0.395\n",
      "x3             0.1282      0.151      0.851      0.395      -0.167       0.424\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691044\n",
      "         Iterations 3\n"
     ]
    }
   ],
   "source": [
    "X_treatment = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "X_treatment = sm.add_constant(X_treatment)\n",
    "\n",
    "y_treatment = df[\"treatment\"]\n",
    "\n",
    "model_treatment = sm.Logit(y_treatment, X_treatment).fit()\n",
    "\n",
    "df[\"p_treatment\"] = model_treatment.predict(X_treatment)\n",
    "df[\"weight_treatment\"] = 1 / df[\"p_treatment\"]\n",
    "\n",
    "print(model_treatment.summary())\n",
    "\n",
    "X_numerator = sm.add_constant(df[[]])\n",
    "model_numerator = sm.Logit(y_treatment, X_numerator).fit()\n",
    "\n",
    "df[\"p_numerator\"] = model_numerator.predict(X_numerator)\n",
    "df[\"stabilized_weight\"] = df[\"p_numerator\"] / df[\"p_treatment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d2cc9-5ad5-4bd1-9b99-790b5e2d3fe6",
   "metadata": {},
   "source": [
    "## **9. Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "88f3ef66-bd66-41ed-aac4-45e2d4eed461",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (712,4) and (5,) not aligned: 4 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict for PP and ITT models\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m pp_predictions \u001b[38;5;241m=\u001b[39m predict_outcomes(msm_pp, trial_pp_expanded, treatment_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     23\u001b[0m itt_predictions \u001b[38;5;241m=\u001b[39m predict_outcomes(msm_itt, trial_itt_loaded, treatment_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicted Outcomes for PP Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[149], line 18\u001b[0m, in \u001b[0;36mpredict_outcomes\u001b[1;34m(model, data, treatment_values)\u001b[0m\n\u001b[0;32m     16\u001b[0m     data_copy[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m     17\u001b[0m     X_pred \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(data_copy[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx3\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m---> 18\u001b[0m     predictions[value] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_pred)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:1176\u001b[0m, in \u001b[0;36mResults.predict\u001b[1;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03mCall self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;124;03mreturned prediction.\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m exog, exog_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_predict_exog(exog,\n\u001b[0;32m   1174\u001b[0m                                                 transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m-> 1176\u001b[0m predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, exog, \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   1177\u001b[0m                                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[0;32m   1180\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predict_results\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:411\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(exog, params)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (712,4) and (5,) not aligned: 4 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "def pp_outcomes(model, data, treatment_values):\n",
    "    \"\"\"\n",
    "    Estimate survival probabilities or cumulative incidences for different values of assigned treatment.\n",
    "    \n",
    "    Parameters:\n",
    "        model (statsmodels object): The fitted regression model.\n",
    "        data (DataFrame): The dataset to make predictions on.\n",
    "        treatment_values (list): List of treatment values to predict for.\n",
    "    \n",
    "    Returns:\n",
    "        predictions (dict): Dictionary containing predictions for each treatment value.\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    for value in treatment_values:\n",
    "        data_copy = data.copy()\n",
    "        data_copy[\"treatment\"] = value\n",
    "        X_pred = sm.add_constant(data_copy[[\"treatment\"] + [\"x1\", \"x2\", \"x3\"]])\n",
    "        predictions[value] = model.predict(X_pred)\n",
    "    return predictions\n",
    "\n",
    "# Predict for PP and ITT models\n",
    "pp_predictions = predict_outcomes(msm_pp, trial_pp_expanded, treatment_values=[0, 1])\n",
    "itt_predictions = predict_outcomes(msm_itt, trial_itt_loaded, treatment_values=[0, 1])\n",
    "\n",
    "print(\"\\nPredicted Outcomes for PP Analysis:\")\n",
    "print(pp_predictions)\n",
    "\n",
    "print(\"\\nPredicted Outcomes for ITT Analysis:\")\n",
    "print(itt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ec6caa55-7fac-4aea-97c9-58653cc3f0ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pp_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Plot predictions\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m plot_predictions(pp_predictions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Outcomes for PP Analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m plot_predictions(itt_predictions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Outcomes for ITT Analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pp_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_predictions(predictions, title):\n",
    "    \"\"\"\n",
    "    Visualize predicted survival probabilities or cumulative incidences.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for treatment, values in predictions.items():\n",
    "        plt.plot(values, label=f'Treatment {treatment}')\n",
    "    plt.xlabel('Observations')\n",
    "    plt.ylabel('Predicted Outcome')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot predictions\n",
    "plot_predictions(pp_predictions, \"Predicted Outcomes for PP Analysis\")\n",
    "plot_predictions(itt_predictions, \"Predicted Outcomes for ITT Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538d83d-644e-4073-9cb8-dadf126f2dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
