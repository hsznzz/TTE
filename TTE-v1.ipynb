{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12b26f5-8776-4c4a-a876-7726e1797e34",
   "metadata": {},
   "source": [
    "# **Target Trial Emulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a6341-9736-4412-8c58-eb38f9e41d08",
   "metadata": {},
   "source": [
    "### **Submitted by:**\n",
    "- **Ladrera**, Raiken\n",
    "- **Tibon**, Hestia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995110c-b937-411b-a74b-e549b35d8fc7",
   "metadata": {},
   "source": [
    "## **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8195ac-f9a9-4240-92a8-c3e7face5e4f",
   "metadata": {},
   "source": [
    "Assignment 1 for Clustering: New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "- Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "- Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "- Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "- Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "- Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "- Do this by pair, preferably your thesis partner.\n",
    "- Push to your github repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52acd26-f363-4cbb-9f2b-ee78ed563c0e",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b290f6f-11b5-4dd2-9b01-eb2fd4a0d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created:\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_pp\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_itt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "estimand_pp = \"PP\"  # Per-protocol\n",
    "estimand_itt = \"ITT\"  # Intention-to-treat\n",
    "\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directories created:\\n{trial_pp_dir}\\n{trial_itt_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ddcb3-eb59-4048-a15f-c94650a8635e",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49319ec8-50dc-4ae8-972a-2ed1dd7381b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Preview:\n",
      "Prepared Data (PP Model):\n",
      "   id  period  treatment  outcome  eligible  age  x1        x2  x3  censored\n",
      "0   1       0          1        0         1   36   1  1.146148   0         0\n",
      "1   1       1          1        0         0   37   1  0.002200   0         0\n",
      "2   1       2          1        0         0   38   0 -0.481762   0         0\n",
      "3   1       3          1        0         0   39   0  0.007872   0         0\n",
      "4   1       4          1        0         0   40   1  0.216054   0         0\n",
      "Prepared Data (ITT Model):\n",
      "   id  period  treatment  outcome  eligible  age  x1        x2  x3  censored\n",
      "0   1       0          1        0         1   36   1  1.146148   0         0\n",
      "1   1       1          1        0         0   37   1  0.002200   0         0\n",
      "2   1       2          1        0         0   38   0 -0.481762   0         0\n",
      "3   1       3          1        0         0   39   0  0.007872   0         0\n",
      "4   1       4          1        0         0   40   1  0.216054   0         0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data_censored.csv\" \n",
    "data_censored = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Initial Data Preview:\")\n",
    "#print(data_censored.head())\n",
    "\n",
    "columns_needed = [\"id\", \"period\", \"treatment\", \"outcome\", \"eligible\", \"age\", \"x1\", \"x2\", \"x3\", \"censored\"]\n",
    "trial_pp = data_censored[columns_needed].copy()\n",
    "trial_itt = data_censored[columns_needed].copy()\n",
    "\n",
    "print(\"Prepared Data (PP Model):\")\n",
    "print(trial_pp.head())\n",
    "\n",
    "print(\"Prepared Data (ITT Model):\")\n",
    "print(trial_itt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63db407-de57-453e-9059-5a20504b6efc",
   "metadata": {},
   "source": [
    "## **3. Weight Models and Censoring**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fb94b-141e-4b36-949f-5da96f54bebb",
   "metadata": {},
   "source": [
    "#### **3.1. Trial Class: Treatment and Censoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8932121-1a30-43cc-9cad-9777f9487f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trial:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.switch_model = None\n",
    "        self.switch_weights = None\n",
    "        self.censor_model = None\n",
    "        self.censor_weights = None\n",
    "        self.numerator = None\n",
    "        self.denominator = None\n",
    "        self.censor_event = None\n",
    "        self.pool_models = None\n",
    "        self.model_fitted = False  \n",
    "\n",
    "    def set_censor_weight_model(self, censor_event, numerator, denominator, pool_models=\"none\"):\n",
    "        self.censor_event = censor_event\n",
    "        self.numerator = numerator\n",
    "        self.denominator = denominator\n",
    "        self.pool_models = pool_models\n",
    "        self.model_fitted = False\n",
    "        print(f\"Censor Model set: 1 - {self.censor_event} ~ {self.numerator} / {self.denominator}\")\n",
    "\n",
    "    def calculate_weights(self, save_path, model_type=\"logit\"):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.data[\"denom\"] = self.data.eval(self.denominator)\n",
    "        self.data[\"censor_binary\"] = 1 - self.data[self.censor_event]\n",
    "        X = sm.add_constant(self.data[\"denom\"])\n",
    "        y = self.data[\"censor_binary\"]\n",
    "        model = sm.Logit(y, X).fit(disp=0)\n",
    "        model.save(os.path.join(save_path, \"censor_model.pickle\"))\n",
    "        self.censor_model = model\n",
    "        self.censor_weights = model.predict(X)\n",
    "        self.model_fitted = True\n",
    "        print(f\"Censor weights saved in {save_path}.\")\n",
    "\n",
    "    @property\n",
    "    def get_censor_weights(self):\n",
    "        if not self.model_fitted:\n",
    "            print(\"Model not fitted. Running `calculate_weights()`...\")\n",
    "            self.calculate_weights(\"trial_default\")\n",
    "        return self.censor_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f84e1b-363e-4a6a-88f7-81383b194144",
   "metadata": {},
   "source": [
    "#### **3.2 Example Usage**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a250e2d-9940-4d57-b5c3-7e0f1b5ed901",
   "metadata": {},
   "source": [
    "**Per-Protocol (PP) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5700e7da-08e7-40d3-a9dd-e224ab08292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Model set: 1 - censored ~ x2 / x2 + x1\n",
      "Model not fitted. Running `calculate_weights()`...\n",
      "Censor weights saved in trial_default.\n",
      "0    0.882943\n",
      "1    0.908124\n",
      "2    0.933494\n",
      "3    0.925940\n",
      "4    0.903820\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "trial_pp = Trial(data_censored)\n",
    "trial_pp.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\"\n",
    ")\n",
    "print(trial_pp.get_censor_weights.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df7ac3-86f8-46e1-ac7d-0fac737eb65a",
   "metadata": {},
   "source": [
    "**Intention-To-Treat (ITT) Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8b9506-e8d5-485b-86c5-650f6674358d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Model set: 1 - censored ~ x2 / x2 + x1\n",
      "Model not fitted. Running `calculate_weights()`...\n",
      "Censor weights saved in trial_default.\n",
      "0    0.882943\n",
      "1    0.908124\n",
      "2    0.933494\n",
      "3    0.925940\n",
      "4    0.903820\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "trial_itt = Trial(data_censored)\n",
    "trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\"\n",
    ")\n",
    "print(trial_itt.get_censor_weights.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a67aa0-689a-469d-83d1-61093dbd4d9d",
   "metadata": {},
   "source": [
    "## **4. Calculate Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "336e4cc4-b82e-4472-8093-cf4bd9f8dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.258039\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      720\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07436\n",
      "Time:                        17:59:49   Log-Likelihood:                -187.08\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.761e-06\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.1848      0.222     -9.839      0.000      -2.620      -1.750\n",
      "x1            -0.6156      0.311     -1.977      0.048      -1.226      -0.005\n",
      "x2             0.5023      0.140      3.578      0.000       0.227       0.777\n",
      "x3            -0.0446      0.288     -0.155      0.877      -0.609       0.519\n",
      "x4             0.5383      0.152      3.531      0.000       0.240       0.837\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_censored.csv\") \n",
    "\n",
    "X = df[[\"x1\", \"x2\",\"x3\",\"x4\"]] \n",
    "X = sm.add_constant(X)  \n",
    "\n",
    "y = df[\"censored\"]  \n",
    "model = sm.Logit(y, X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57aa31f7-fe70-4bae-a449-885e09e0b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s',\n",
      "       'outcome', 'censored', 'eligible'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16df47d-88b4-401d-bf53-4f9286ff2016",
   "metadata": {},
   "source": [
    "## **5. Specify Outcome Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579725f-adcb-431a-9789-abc68821c694",
   "metadata": {},
   "source": [
    "***Fit Logistic Regression Models to Estimate Probabilities.*** \n",
    "\n",
    "In R, calculate_weights() estimates models for censoring and treatment assignment separately. You can fit another logistic regression model by having *treatment weights*. Using *stabilized weights* (like in R), you need to estimate the numerator model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e442a9-d225-4dce-9df1-a226e6e8020b",
   "metadata": {},
   "source": [
    "**Censored:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e6db65-c6cd-427a-a91d-79552042ecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.267425\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      722\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.04069\n",
      "Time:                        17:59:53   Log-Likelihood:                -193.88\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002679\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.2059      0.165    -13.339      0.000      -2.530      -1.882\n",
      "x1            -0.7019      0.307     -2.285      0.022      -1.304      -0.100\n",
      "x2             0.4706      0.137      3.423      0.001       0.201       0.740\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "X_censor = df[[\"x1\", \"x2\"]]\n",
    "X_censor = sm.add_constant(X_censor)\n",
    "\n",
    "y_censor = df[\"censored\"]\n",
    "\n",
    "model_censor = sm.Logit(y_censor, X_censor).fit()\n",
    "\n",
    "df[\"p_censor\"] = model_censor.predict(X_censor)\n",
    "df[\"weight_censor\"] = 1 / df[\"p_censor\"]\n",
    "\n",
    "print(model_censor.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5b9a5-d862-4ef9-ba4b-47e54142f774",
   "metadata": {},
   "source": [
    "**Treatment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbffcd61-ff78-4501-91da-189dd2ae35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682194\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      721\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.01281\n",
      "Time:                        17:59:55   Log-Likelihood:                -494.59\n",
      "converged:                       True   LL-Null:                       -501.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.005012\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.2294      0.124     -1.850      0.064      -0.472       0.014\n",
      "x1             0.1908      0.153      1.246      0.213      -0.109       0.491\n",
      "x2             0.2444      0.077      3.178      0.001       0.094       0.395\n",
      "x3             0.1282      0.151      0.851      0.395      -0.167       0.424\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691044\n",
      "         Iterations 3\n"
     ]
    }
   ],
   "source": [
    "X_treatment = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "X_treatment = sm.add_constant(X_treatment)\n",
    "\n",
    "y_treatment = df[\"treatment\"]\n",
    "\n",
    "model_treatment = sm.Logit(y_treatment, X_treatment).fit()\n",
    "\n",
    "df[\"p_treatment\"] = model_treatment.predict(X_treatment)\n",
    "df[\"weight_treatment\"] = 1 / df[\"p_treatment\"]\n",
    "\n",
    "print(model_treatment.summary())\n",
    "\n",
    "X_numerator = sm.add_constant(df[[]])\n",
    "model_numerator = sm.Logit(y_treatment, X_numerator).fit()\n",
    "\n",
    "df[\"p_numerator\"] = model_numerator.predict(X_numerator)\n",
    "df[\"stabilized_weight\"] = df[\"p_numerator\"] / df[\"p_treatment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a9353-bb76-47ec-ab91-866bb4a361e2",
   "metadata": {},
   "source": [
    "## **6.Expand Trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7266ec6-320b-4081-92cb-26283a2c7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df[\"trial_period\"] = 0\n",
    "df[\"followup_time\"] = 0\n",
    "\n",
    "def expand_trials(df, chunk_size=500):\n",
    "    expanded_data = []\n",
    "    \n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        chunk = df.iloc[i:i + chunk_size].copy()\n",
    "        chunk[\"trial_period\"] = 0  \n",
    "        chunk[\"followup_time\"] = 0  \n",
    "        expanded_data.append(chunk)\n",
    "    \n",
    "    return pd.concat(expanded_data, ignore_index=True)\n",
    "\n",
    "df_expanded = expand_trials(df, chunk_size=500)\n",
    "\n",
    "def load_expanded_data(df, seed=1234, p_control=0.5):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    df_sampled = df.copy()\n",
    "    \n",
    "    if \"outcome\" in df_sampled.columns:\n",
    "        mask = (df_sampled[\"outcome\"] == 0) & (np.random.rand(len(df_sampled)) > p_control)\n",
    "        df_sampled = df_sampled[~mask]\n",
    "    \n",
    "    return df_sampled\n",
    "\n",
    "df_loaded = load_expanded_data(df_expanded, seed=1234, p_control=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06b3fb80-a86d-489f-8817-8e6ce1fa9f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trial_period  count\n",
      "0             0    725\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "  trial_period followup_time        outcome     stabilized_weight            \n",
      "                        mean  std      mean sum              mean         sum\n",
      "0            0           0.0  0.0  0.015172  11          1.020809  740.086598\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Trial Period: 0\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  p_censor  weight_censor  p_treatment  weight_treatment  \\\n",
      "0         0         1  0.085615      11.680227     0.560088          1.785434   \n",
      "1         0         0  0.051819      19.297919     0.490483          2.038809   \n",
      "2         0         0  0.080719      12.388616     0.414082          2.414983   \n",
      "3         0         0  0.099556      10.044620     0.443383          2.255389   \n",
      "4         0         0  0.056993      17.545900     0.503548          1.985907   \n",
      "\n",
      "   p_numerator  stabilized_weight  trial_period  followup_time  \n",
      "0     0.467586           0.834844             0              0  \n",
      "1     0.467586           0.953319             0              0  \n",
      "2     0.467586           1.129213             0              0  \n",
      "3     0.467586           1.054589             0              0  \n",
      "4     0.467586           0.928583             0              0  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trial_summary = df_expanded.groupby(\"trial_period\").size().reset_index(name=\"count\")\n",
    "print(trial_summary)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "trial_summary = df_expanded.groupby(\"trial_period\").agg({\n",
    "    \"followup_time\": [\"mean\", \"std\"],\n",
    "    \"outcome\": [\"mean\", \"sum\"],\n",
    "    \"stabilized_weight\": [\"mean\", \"sum\"]  # Use the correct weight column\n",
    "}).reset_index()\n",
    "\n",
    "print(trial_summary)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "for period, group in df_expanded.groupby(\"trial_period\"):\n",
    "    print(f\"Trial Period: {period}\")\n",
    "    print(group.head())  # Show first few records for each trial period\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664982c6-142e-4e11-a800-34aa77e05802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
