{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12b26f5-8776-4c4a-a876-7726e1797e34",
   "metadata": {},
   "source": [
    "# **Target Trial Emulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a6341-9736-4412-8c58-eb38f9e41d08",
   "metadata": {},
   "source": [
    "### **Submitted by:**\n",
    "- **Ladrera**, Raiken\n",
    "- **Tibon**, Hestia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995110c-b937-411b-a74b-e549b35d8fc7",
   "metadata": {},
   "source": [
    "## **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8195ac-f9a9-4240-92a8-c3e7face5e4f",
   "metadata": {},
   "source": [
    "Assignment 1 for Clustering: New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "- Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "- Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "- Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "- Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "- Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "- Do this by pair, preferably your thesis partner.\n",
    "- Push to your github repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52acd26-f363-4cbb-9f2b-ee78ed563c0e",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e6bb922-7be2-4b1e-bf7d-6298a0b94219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP directory: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_pp\n",
      "ITT directory: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_itt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "print(f\"PP directory: {trial_pp_dir}\")\n",
    "print(f\"ITT directory: {trial_itt_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ddcb3-eb59-4048-a15f-c94650a8635e",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eeeac09d-9941-4219-af83-9d47898c3d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Preview:\n",
      "\n",
      "Prepared data (PP Model):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "\n",
      "Prepared data (ITT Model):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n"
     ]
    }
   ],
   "source": [
    "data_censored = pd.read_csv('data_censored.csv')\n",
    "\n",
    "print(\"Initial Data Preview:\")\n",
    "#print(data_censored.head())\n",
    "\n",
    "def set_data(data, id_col, period, treatment, outcome, eligible):\n",
    "    df = dict()\n",
    "    df['data'] = data.copy()\n",
    "    df['id'] = id_col\n",
    "    df['period'] = period\n",
    "    df['treatment'] = treatment\n",
    "    df['outcome'] = outcome\n",
    "    df['eligible'] = eligible\n",
    "\n",
    "    return df\n",
    "\n",
    "trial_pp = set_data(data=data_censored, id_col=\"id\", period=\"period\",\n",
    "                    treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\")\n",
    "trial_itt = set_data(data=data_censored, id_col=\"id\", period=\"period\",\n",
    "                     treatment=\"treatment\", outcome=\"outcome\", eligible=\"eligible\")\n",
    "\n",
    "print(\"\\nPrepared data (PP Model):\")\n",
    "print(trial_pp['data'].head())\n",
    "print(\"\\nPrepared data (ITT Model):\")\n",
    "print(trial_itt['data'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63db407-de57-453e-9059-5a20504b6efc",
   "metadata": {},
   "source": [
    "## **3. Weight Models and Censoring**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fb94b-141e-4b36-949f-5da96f54bebb",
   "metadata": {},
   "source": [
    "#### **3.1. Trial Class: Treatment and Censoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8932121-1a30-43cc-9cad-9777f9487f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows with switch weights (PP):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  switch_weight  \n",
      "0         0         1       0.930088  \n",
      "1         0         0       0.928634  \n",
      "2         0         0       1.039459  \n",
      "3         0         0       1.040816  \n",
      "4         0         0       0.924292  \n"
     ]
    }
   ],
   "source": [
    "def fit_logistic_model(X, y):\n",
    "    \"\"\"\n",
    "    Fit a logistic regression model using statsmodels.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "    return model\n",
    "\n",
    "def predict_prob(model, X):\n",
    "    \"\"\"\n",
    "    Predict probabilities from a logistic regression model.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)\n",
    "    return model.predict(X)\n",
    "\n",
    "def set_switch_weight_model(data, numerator, denominator, model_fitter=fit_logistic_model, save_path=None):\n",
    "    \"\"\"\n",
    "    Fit the switch weight model for treatment switching.\n",
    "    \"\"\"\n",
    "    # Parse formulas\n",
    "    num_formula = numerator.replace(\"~\", \"\").strip()\n",
    "    num_vars = [v.strip() for v in num_formula.split(\"+\")]\n",
    "\n",
    "    den_formula = denominator.replace(\"~\", \"\").strip()\n",
    "    den_vars = [v.strip() for v in den_formula.split(\"+\")]\n",
    "\n",
    "    # Fit numerator model: treatment ~ (numerator variables)\n",
    "    X_num = data[num_vars]\n",
    "    y_treatment = data[\"treatment\"]\n",
    "    num_model = model_fitter(X_num, y_treatment)\n",
    "\n",
    "    # Fit denominator model: treatment ~ (denominator variables)\n",
    "    X_den = data[den_vars]\n",
    "    den_model = model_fitter(X_den, y_treatment)\n",
    "\n",
    "    p_num = predict_prob(num_model, X_num)\n",
    "    p_den = predict_prob(den_model, X_den)\n",
    "\n",
    "    data = data.copy()\n",
    "    data[\"switch_weight\"] = p_num / p_den\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        with open(os.path.join(save_path, \"switch_model_num.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(num_model, f)\n",
    "        with open(os.path.join(save_path, \"switch_model_den.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(den_model, f)\n",
    "\n",
    "    return {\"data\": data, \"numerator_model\": num_model, \"denominator_model\": den_model,\n",
    "            \"switch_weights\": data[\"switch_weight\"]}\n",
    "\n",
    "switch_results = set_switch_weight_model(\n",
    "    data=trial_pp['data'],\n",
    "    numerator=\"~ age\",\n",
    "    denominator=\"~ age + x1 + x3\",\n",
    "    model_fitter=fit_logistic_model,\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "trial_pp['data'] = switch_results[\"data\"]\n",
    "\n",
    "print(\"\\nFirst few rows with switch weights (PP):\")\n",
    "print(trial_pp['data'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fead91-70df-4fe9-815e-7e33cded660c",
   "metadata": {},
   "source": [
    "### **3.2 Other Informative Censoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c3bd031-b894-44a8-8ac0-1583d66ad84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved at: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_pp\\switch_models\\switch_model_num.pkl and C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_pp\\switch_models\\switch_model_den.pkl\n",
      "\n",
      "First few rows with censor weights (PP):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  switch_weight  not_censored  censor_weight  \n",
      "0         0         1       0.930088             1       0.955481  \n",
      "1         0         0       0.928634             1       0.970647  \n",
      "2         0         0       1.039459             1       1.016972  \n",
      "3         0         0       1.040816             1       1.021899  \n",
      "4         0         0       0.924292             1       0.968208  \n",
      "Models saved at: C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_itt\\switch_models\\switch_model_num.pkl and C:\\Users\\meizi\\AppData\\Local\\Temp\\trial_itt\\switch_models\\switch_model_den.pkl\n",
      "\n",
      "First few rows with censor weights (ITT):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  not_censored  censor_weight  \n",
      "0         0         1             1       0.955481  \n",
      "1         0         0             1       0.970647  \n",
      "2         0         0             1       1.016972  \n",
      "3         0         0             1       1.021899  \n",
      "4         0         0             1       0.968208  \n"
     ]
    }
   ],
   "source": [
    "def set_censor_weight_model(data, censor_event, numerator, denominator, pool_models=\"none\",\n",
    "                            model_fitter=fit_logistic_model, save_path=None):\n",
    "   \n",
    "    data = data.copy()\n",
    "    data[\"not_censored\"] = 1 - data[censor_event]\n",
    "\n",
    "    # Parse numerator formula\n",
    "    num_formula = numerator.replace(\"~\", \"\").strip()\n",
    "    num_vars = [v.strip() for v in num_formula.split(\"+\")]\n",
    "    # Parse denominator formula\n",
    "    den_formula = denominator.replace(\"~\", \"\").strip()\n",
    "    den_vars = [v.strip() for v in den_formula.split(\"+\")]\n",
    "\n",
    "    X_num = data[num_vars]\n",
    "    y_nc = data[\"not_censored\"]\n",
    "    num_model = model_fitter(X_num, y_nc)\n",
    "\n",
    "    # Fit denominator model: not_censored ~ x2 + x1\n",
    "    X_den = data[den_vars]\n",
    "    den_model = model_fitter(X_den, y_nc)\n",
    "\n",
    "    p_num = predict_prob(num_model, X_num)\n",
    "    p_den = predict_prob(den_model, X_den)\n",
    "\n",
    "    data[\"censor_weight\"] = p_num / p_den\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        num_path = os.path.join(save_path, \"switch_model_num.pkl\")\n",
    "        den_path = os.path.join(save_path, \"switch_model_den.pkl\")\n",
    "        with open(num_path, \"wb\") as f:\n",
    "            pickle.dump(num_model, f)\n",
    "        with open(den_path, \"wb\") as f:\n",
    "            pickle.dump(den_model, f)\n",
    "        print(f\"Models saved at: {num_path} and {den_path}\")\n",
    "\n",
    "    return {\"data\": data, \"numerator_model\": num_model, \"denominator_model\": den_model,\n",
    "            \"censor_weights\": data[\"censor_weight\"]}\n",
    "\n",
    "censor_results_pp = set_censor_weight_model(\n",
    "    data=trial_pp['data'],\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"~ x2\",\n",
    "    denominator=\"~ x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=fit_logistic_model,\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "trial_pp['data'] = censor_results_pp[\"data\"]\n",
    "print(\"\\nFirst few rows with censor weights (PP):\")\n",
    "print(trial_pp['data'].head())\n",
    "\n",
    "censor_results_itt = set_censor_weight_model(\n",
    "    data=trial_itt['data'],\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"~ x2\",\n",
    "    denominator=\"~ x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    model_fitter=fit_logistic_model,\n",
    "    save_path=os.path.join(trial_itt_dir, \"switch_models\")\n",
    ")\n",
    "trial_itt['data'] = censor_results_itt[\"data\"]\n",
    "print(\"\\nFirst few rows with censor weights (ITT):\")\n",
    "print(trial_itt['data'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a67aa0-689a-469d-83d1-61093dbd4d9d",
   "metadata": {},
   "source": [
    "## **4. Calculate Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "336e4cc4-b82e-4472-8093-cf4bd9f8dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows with overall PP weights:\n",
      "   id  PP_weight\n",
      "0   1   0.888682\n",
      "1   1   0.901376\n",
      "2   1   1.057101\n",
      "3   1   1.063608\n",
      "4   1   0.894907\n",
      "\n",
      "First few rows with ITT weights:\n",
      "   id  ITT_weight\n",
      "0   1    0.955481\n",
      "1   1    0.970647\n",
      "2   1    1.016972\n",
      "3   1    1.021899\n",
      "4   1    0.968208\n"
     ]
    }
   ],
   "source": [
    "# PP | overall weight is the product of switch and censor weights.\n",
    "trial_pp['data'][\"PP_weight\"] = trial_pp['data'][\"switch_weight\"] * trial_pp['data'][\"censor_weight\"]\n",
    "\n",
    "# ITT | Weight is simply the censor weight.\n",
    "trial_itt['data'][\"ITT_weight\"] = trial_itt['data'][\"censor_weight\"]\n",
    "\n",
    "print(\"\\nFirst few rows with overall PP weights:\")\n",
    "print(trial_pp['data'][[\"id\", \"PP_weight\"]].head())\n",
    "print(\"\\nFirst few rows with ITT weights:\")\n",
    "print(trial_itt['data'][[\"id\", \"ITT_weight\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "57aa31f7-fe70-4bae-a449-885e09e0b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s',\n",
      "       'outcome', 'censored', 'eligible', 'trial_period', 'followup_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16df47d-88b4-401d-bf53-4f9286ff2016",
   "metadata": {},
   "source": [
    "## **5. Specify Outcome Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3fb1a682-de82-4114-a67e-04ffbca01616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_outcome_model(data, adjustment_terms=None):\n",
    "    \"\"\"\n",
    "    Returns: Data with an added column named 'adjustment_terms'.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data[\"adjustment_terms\"] = adjustment_terms if adjustment_terms is not None else \"\"\n",
    "    return data\n",
    "\n",
    "trial_pp['data'] = set_outcome_model(trial_pp['data'])\n",
    "trial_itt['data'] = set_outcome_model(trial_itt['data'], adjustment_terms=\"x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a9353-bb76-47ec-ab91-866bb4a361e2",
   "metadata": {},
   "source": [
    "## **6.Expand Trials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f30955b5-159d-42ab-b7a2-740c52af1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of Expanded Per-protocol data (PP):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "2   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "3   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "4   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "\n",
      "   censored  eligible  switch_weight  not_censored  censor_weight  PP_weight  \\\n",
      "0         0         1       0.930088             1       0.955481   0.888682   \n",
      "1         0         1       0.930088             1       0.955481   0.888682   \n",
      "2         0         1       0.930088             1       0.955481   0.888682   \n",
      "3         0         1       0.930088             1       0.955481   0.888682   \n",
      "4         0         1       0.930088             1       0.955481   0.888682   \n",
      "\n",
      "  adjustment_terms  trial_period  followup_time  \n",
      "0                              0              0  \n",
      "1                              1              1  \n",
      "2                              2              2  \n",
      "3                              3              3  \n",
      "4                              4              4  \n",
      "\n",
      "First few rows of Expanded Intention-to-Treat data (ITT):\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "2   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "3   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "4   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "\n",
      "   censored  eligible  not_censored  censor_weight  ITT_weight  \\\n",
      "0         0         1             1       0.955481    0.955481   \n",
      "1         0         1             1       0.955481    0.955481   \n",
      "2         0         1             1       0.955481    0.955481   \n",
      "3         0         1             1       0.955481    0.955481   \n",
      "4         0         1             1       0.955481    0.955481   \n",
      "\n",
      "  adjustment_terms  trial_period  followup_time  \n",
      "0               x2             0              0  \n",
      "1               x2             1              1  \n",
      "2               x2             2              2  \n",
      "3               x2             3              3  \n",
      "4               x2             4              4  \n"
     ]
    }
   ],
   "source": [
    "def expand_trials(data, chunk_size=500, first_period=0, last_period=None):\n",
    "    \"\"\"\n",
    "    Returns: Expanded data with new columns named 'trial_period' and 'followup_time'\n",
    "    \"\"\"\n",
    "    if last_period is None:\n",
    "        last_period = first_period + 7  # e.g., 0 to 7\n",
    "\n",
    "    expanded_list = []\n",
    "    for pid, group in data.groupby(\"id\"):\n",
    "        baseline = group.iloc[0].to_dict()\n",
    "        for trial_period in range(first_period, last_period + 1):\n",
    "            row = baseline.copy()\n",
    "            row[\"trial_period\"] = trial_period\n",
    "            row[\"followup_time\"] = trial_period\n",
    "            expanded_list.append(row)\n",
    "    return pd.DataFrame(expanded_list)\n",
    "\n",
    "trial_pp_expanded = expand_trials(trial_pp['data'], chunk_size=500)\n",
    "trial_itt_expanded = expand_trials(trial_itt['data'], chunk_size=500)\n",
    "\n",
    "print(\"\\nFirst few rows of Expanded Per-protocol data (PP):\")\n",
    "print(trial_pp_expanded.head())\n",
    "print(\"\\nFirst few rows of Expanded Intention-to-Treat data (ITT):\")\n",
    "print(trial_itt_expanded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9914f-86cc-4502-bae2-a68ea0d9e889",
   "metadata": {},
   "source": [
    "## **7.Load Sample from Expanded Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a9491ed1-19b3-4705-8866-22187939b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of ITT expanded observations after sampling: 364\n"
     ]
    }
   ],
   "source": [
    "def load_expanded_data(data, seed=1234, p_control=0.5):\n",
    "    np.random.seed(seed)\n",
    "    events = data[data[\"outcome\"] == 1]\n",
    "    non_events = data[data[\"outcome\"] == 0].sample(frac=p_control, random_state=seed)\n",
    "    return pd.concat([events, non_events], ignore_index=True)\n",
    "\n",
    "trial_itt_loaded = load_expanded_data(trial_itt_expanded, seed=1234, p_control=0.5)\n",
    "print(\"\\nNumber of ITT expanded observations after sampling:\", trial_itt_loaded.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec44671-63bc-415f-851e-074f18965439",
   "metadata": {},
   "source": [
    "## **8.Fit Marginal Structural Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4ed4242f-c912-49be-adfb-895e80f79a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Marginal Structural Model (MSM) Summary:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  364\n",
      "Model:                            GLM   Df Residuals:                   359.49\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Sun, 09 Mar 2025   Deviance:                       1440.9\n",
      "Time:                        20:27:36   Pearson chi2:                 7.05e+16\n",
      "No. Iterations:                    22   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const              -2.239e+15   9.09e+06  -2.46e+08      0.000   -2.24e+15   -2.24e+15\n",
      "assigned_treatment  8.675e+14   7.05e+06   1.23e+08      0.000    8.68e+14    8.68e+14\n",
      "x2                 -4.104e+13   3.94e+06  -1.04e+07      0.000    -4.1e+13    -4.1e+13\n",
      "followup_time       1.141e+14   2.82e+06   4.05e+07      0.000    1.14e+14    1.14e+14\n",
      "followup_time_sq   -9.936e+12   3.88e+05  -2.56e+07      0.000   -9.94e+12   -9.94e+12\n",
      "trial_period        1.141e+14   2.82e+06   4.05e+07      0.000    1.14e+14    1.14e+14\n",
      "trial_period_sq    -9.936e+12   3.88e+05  -2.56e+07      0.000   -9.94e+12   -9.94e+12\n",
      "======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "# For ITT: prepare the data for outcome modeling\n",
    "trial_itt_loaded = trial_itt_loaded.copy()\n",
    "trial_itt_loaded[\"assigned_treatment\"] = trial_itt_loaded[\"treatment\"]\n",
    "trial_itt_loaded[\"followup_time_sq\"] = trial_itt_loaded[\"followup_time\"] ** 2\n",
    "trial_itt_loaded[\"trial_period_sq\"] = trial_itt_loaded[\"trial_period\"] ** 2\n",
    "\n",
    "# Merge in ITT weights from the original trial_itt data (one per patient)\n",
    "weights_df = trial_itt['data'][[\"id\"]].drop_duplicates()\n",
    "trial_itt_loaded = trial_itt_loaded.merge(weights_df, on=\"id\", how=\"left\")\n",
    "\n",
    "# Winsorize weights: cap at 99th percentile\n",
    "w99 = trial_itt_loaded[\"ITT_weight\"].quantile(0.99)\n",
    "trial_itt_loaded[\"winsorized_weight\"] = np.minimum(trial_itt_loaded[\"ITT_weight\"], w99)\n",
    "\n",
    "# Define predictors per outcome model specification:\n",
    "# outcome ~ assigned_treatment + x2 + followup_time + followup_time^2 + trial_period + trial_period^2\n",
    "predictors = [\"assigned_treatment\", \"x2\", \"followup_time\", \"followup_time_sq\", \"trial_period\", \"trial_period_sq\"]\n",
    "X = trial_itt_loaded[predictors]\n",
    "X = sm.add_constant(X)\n",
    "y = trial_itt_loaded[\"outcome\"]\n",
    "\n",
    "# Fit the weighted logistic regression (MSM)\n",
    "msm_model = sm.GLM(y, X, family=sm.families.Binomial(), freq_weights=trial_itt_loaded[\"winsorized_weight\"]).fit()\n",
    "print(\"\\nMarginal Structural Model (MSM) Summary:\")\n",
    "print(mo_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e442a9-d225-4dce-9df1-a226e6e8020b",
   "metadata": {},
   "source": [
    "**Censored:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e6db65-c6cd-427a-a91d-79552042ecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.267425\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      722\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.04069\n",
      "Time:                        17:59:53   Log-Likelihood:                -193.88\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0002679\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.2059      0.165    -13.339      0.000      -2.530      -1.882\n",
      "x1            -0.7019      0.307     -2.285      0.022      -1.304      -0.100\n",
      "x2             0.4706      0.137      3.423      0.001       0.201       0.740\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_censored.csv\")\n",
    "\n",
    "X_censor = df[[\"x1\", \"x2\"]]\n",
    "X_censor = sm.add_constant(X_censor)\n",
    "\n",
    "y_censor = df[\"censored\"]\n",
    "\n",
    "model_censor = sm.Logit(y_censor, X_censor).fit()\n",
    "\n",
    "df[\"p_censor\"] = model_censor.predict(X_censor)\n",
    "df[\"weight_censor\"] = 1 / df[\"p_censor\"]\n",
    "\n",
    "print(model_censor.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5b9a5-d862-4ef9-ba4b-47e54142f774",
   "metadata": {},
   "source": [
    "**Treatment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbffcd61-ff78-4501-91da-189dd2ae35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682194\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      721\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.01281\n",
      "Time:                        17:59:55   Log-Likelihood:                -494.59\n",
      "converged:                       True   LL-Null:                       -501.01\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.005012\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.2294      0.124     -1.850      0.064      -0.472       0.014\n",
      "x1             0.1908      0.153      1.246      0.213      -0.109       0.491\n",
      "x2             0.2444      0.077      3.178      0.001       0.094       0.395\n",
      "x3             0.1282      0.151      0.851      0.395      -0.167       0.424\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691044\n",
      "         Iterations 3\n"
     ]
    }
   ],
   "source": [
    "X_treatment = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "X_treatment = sm.add_constant(X_treatment)\n",
    "\n",
    "y_treatment = df[\"treatment\"]\n",
    "\n",
    "model_treatment = sm.Logit(y_treatment, X_treatment).fit()\n",
    "\n",
    "df[\"p_treatment\"] = model_treatment.predict(X_treatment)\n",
    "df[\"weight_treatment\"] = 1 / df[\"p_treatment\"]\n",
    "\n",
    "print(model_treatment.summary())\n",
    "\n",
    "X_numerator = sm.add_constant(df[[]])\n",
    "model_numerator = sm.Logit(y_treatment, X_numerator).fit()\n",
    "\n",
    "df[\"p_numerator\"] = model_numerator.predict(X_numerator)\n",
    "df[\"stabilized_weight\"] = df[\"p_numerator\"] / df[\"p_treatment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d2cc9-5ad5-4bd1-9b99-790b5e2d3fe6",
   "metadata": {},
   "source": [
    "## **9. Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "88f3ef66-bd66-41ed-aac4-45e2d4eed461",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'msm_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add predicted survival probabilities to the expanded dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trial_pp_expanded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_survival\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m msm_results\u001b[38;5;241m.\u001b[39mpredict(exog\u001b[38;5;241m=\u001b[39mtrial_pp_expanded)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Aggregate predictions by time\u001b[39;00m\n\u001b[0;32m      5\u001b[0m aggregated_predictions \u001b[38;5;241m=\u001b[39m trial_pp_expanded\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial_period\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_survival\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'msm_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Add predicted survival probabilities to the expanded dataset\n",
    "trial_pp_expanded[\"predicted_survival\"] = msm_results.predict(exog=trial_pp_expanded)\n",
    "\n",
    "# Aggregate predictions by time\n",
    "aggregated_predictions = trial_pp_expanded.groupby(\"trial_period\")[\"predicted_survival\"].mean()\n",
    "\n",
    "# Plot survival probability\n",
    "plt.plot(aggregated_predictions.index, aggregated_predictions.values, label=\"Survival Probability\")\n",
    "plt.xlabel(\"Follow-up Time\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.title(\"Survival Probability Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6caa55-7fac-4aea-97c9-58653cc3f0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
