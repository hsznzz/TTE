{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12b26f5-8776-4c4a-a876-7726e1797e34",
   "metadata": {},
   "source": [
    "# **Target Trial Emulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a6341-9736-4412-8c58-eb38f9e41d08",
   "metadata": {},
   "source": [
    "### **Submitted by:**\n",
    "- **Ladrera**, Raiken\n",
    "- **Tibon**, Hestia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995110c-b937-411b-a74b-e549b35d8fc7",
   "metadata": {},
   "source": [
    "## **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8195ac-f9a9-4240-92a8-c3e7face5e4f",
   "metadata": {},
   "source": [
    "Assignment 1 for Clustering: New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "- Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "- Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "- Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "- Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "- Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "- Do this by pair, preferably your thesis partner.\n",
    "- Push to your github repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52acd26-f363-4cbb-9f2b-ee78ed563c0e",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b290f6f-11b5-4dd2-9b01-eb2fd4a0d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created:\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_pp\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_itt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "estimand_pp = \"PP\"  # Per-protocol\n",
    "estimand_itt = \"ITT\"  # Intention-to-treat\n",
    "\n",
    "# Directories for saving outputs\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directories created:\\n{trial_pp_dir}\\n{trial_itt_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ddcb3-eb59-4048-a15f-c94650a8635e",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49319ec8-50dc-4ae8-972a-2ed1dd7381b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "   id  period  treatment  outcome  eligible  age  x1        x2  x3\n",
      "0   1       0          1        0         1   36   1  1.146148   0\n",
      "1   1       1          1        0         0   37   1  0.002200   0\n",
      "2   1       2          1        0         0   38   0 -0.481762   0\n",
      "3   1       3          1        0         0   39   0  0.007872   0\n",
      "4   1       4          1        0         0   40   1  0.216054   0\n",
      "   id  period  treatment  outcome  eligible  age  x1        x2  x3\n",
      "0   1       0          1        0         1   36   1  1.146148   0\n",
      "1   1       1          1        0         0   37   1  0.002200   0\n",
      "2   1       2          1        0         0   38   0 -0.481762   0\n",
      "3   1       3          1        0         0   39   0  0.007872   0\n",
      "4   1       4          1        0         0   40   1  0.216054   0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data_censored.csv\" \n",
    "data_censored = pd.read_csv(data_path)\n",
    "print(data_censored.head())\n",
    "\n",
    "columns_needed = [\"id\", \"period\", \"treatment\", \"outcome\", \"eligible\", \"age\", \"x1\", \"x2\", \"x3\"]\n",
    "trial_pp = data_censored[columns_needed].copy()\n",
    "trial_itt = data_censored[columns_needed].copy()\n",
    "\n",
    "print(trial_pp.head())\n",
    "print(trial_itt.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63db407-de57-453e-9059-5a20504b6efc",
   "metadata": {},
   "source": [
    "## **3. Weight Models and Censoring**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fb94b-141e-4b36-949f-5da96f54bebb",
   "metadata": {},
   "source": [
    "#### **3.1. Treatment and Switching Weight Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8932121-1a30-43cc-9cad-9777f9487f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor Model specifications set:\n",
      "- Numerator formula: 1 - censored ~ x2\n",
      "- Denominator formula: 1 - censored ~ x2 + x1\n",
      "- Pooling: none\n",
      "- Model not fitted yet. Use `calculate_weights()`.\n",
      "Censor model not fitted yet. Automatically running `calculate_weights()`...\n",
      "Censor weights calculated and saved in trial_default.\n",
      "0    0.882943\n",
      "1    0.908124\n",
      "2    0.933494\n",
      "3    0.925940\n",
      "4    0.903820\n",
      "dtype: float64\n",
      "Censor Model specifications set:\n",
      "- Numerator formula: 1 - censored ~ x2\n",
      "- Denominator formula: 1 - censored ~ x2 + x1\n",
      "- Pooling: numerator\n",
      "- Model not fitted yet. Use `calculate_weights()`.\n",
      "Censor model not fitted yet. Automatically running `calculate_weights()`...\n",
      "Censor weights calculated and saved in trial_default.\n",
      "0    0.882943\n",
      "1    0.908124\n",
      "2    0.933494\n",
      "3    0.925940\n",
      "4    0.903820\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "class Trial:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Initialize the trial object with dataset.\"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.switch_model = None\n",
    "        self.switch_weights = None\n",
    "        self.censor_model = None\n",
    "        self.censor_weights = None\n",
    "        self.numerator = None\n",
    "        self.denominator = None\n",
    "        self.censor_event = None\n",
    "        self.pool_models = None\n",
    "        self.model_fitted = False  \n",
    "\n",
    "    def set_switch_weight_model(self, numerator, denominator):\n",
    "        \"\"\"Set up the numerator and denominator formulas for switch weight modeling.\"\"\"\n",
    "        self.numerator = numerator\n",
    "        self.denominator = denominator\n",
    "        self.model_fitted = False \n",
    "        \n",
    "        print(f\"Switch Model specifications set:\\n\"\n",
    "              f\"- Numerator: {self.numerator}\\n\"\n",
    "              f\"- Denominator: {self.denominator}\\n\"\n",
    "              f\"- Model not fitted yet. Use `calculate_weights()`.\")\n",
    "\n",
    "    def set_censor_weight_model(self, censor_event, numerator, denominator, pool_models=\"none\"):\n",
    "        \"\"\"Set up the numerator and denominator formulas for censor weight modeling.\"\"\"\n",
    "        self.censor_event = censor_event\n",
    "        self.numerator = numerator\n",
    "        self.denominator = denominator\n",
    "        self.pool_models = pool_models\n",
    "        self.model_fitted = False  # Reset model status\n",
    "\n",
    "        print(f\"Censor Model specifications set:\\n\"\n",
    "              f\"- Numerator formula: 1 - {self.censor_event} ~ {self.numerator}\\n\"\n",
    "              f\"- Denominator formula: 1 - {self.censor_event} ~ {self.denominator}\\n\"\n",
    "              f\"- Pooling: {self.pool_models}\\n\"\n",
    "              f\"- Model not fitted yet. Use `calculate_weights()`.\")\n",
    "\n",
    "    def calculate_weights(self, save_path, model_type=\"logit\", weight_type=\"switch\"):\n",
    "        \"\"\"Fit logistic regression model and compute weights.\"\"\"\n",
    "        if weight_type == \"switch\":\n",
    "            # Ensure formulas exist\n",
    "            if self.numerator is None or self.denominator is None:\n",
    "                raise ValueError(\"Switch weight model formulas not set. Call `set_switch_weight_model()` first.\")\n",
    "\n",
    "            # Ensure output directory exists\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "            # Compute denominator variable\n",
    "            self.data[\"denom\"] = self.data.eval(self.denominator)\n",
    "\n",
    "            # Convert age to binary if needed\n",
    "            median_age = self.data[\"age\"].median()\n",
    "            self.data[\"age_binary\"] = (self.data[\"age\"] > median_age).astype(int)\n",
    "\n",
    "            # Prepare independent (X) and dependent (y) variables\n",
    "            X = sm.add_constant(self.data[\"denom\"])\n",
    "            y = self.data[\"age_binary\"]\n",
    "\n",
    "            # Choose model type\n",
    "            if model_type == \"logit\":\n",
    "                model = sm.Logit(y, X).fit(disp=0)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported model type. Only 'logit' is available for now.\")\n",
    "\n",
    "            # Save model\n",
    "            model.save(os.path.join(save_path, \"switch_model.pickle\"))\n",
    "\n",
    "            # Store results\n",
    "            self.switch_model = model\n",
    "            self.switch_weights = model.predict(X)\n",
    "            self.model_fitted = True\n",
    "\n",
    "            print(f\"Switch weights calculated and saved in {save_path}.\")\n",
    "\n",
    "        elif weight_type == \"censor\":\n",
    "            # Ensure formulas exist\n",
    "            if self.censor_event is None or self.numerator is None or self.denominator is None:\n",
    "                raise ValueError(\"Censor weight model formulas not set. Call `set_censor_weight_model()` first.\")\n",
    "\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "            # Compute denominator variable\n",
    "            self.data[\"denom\"] = self.data.eval(self.denominator)\n",
    "\n",
    "            # Define censor outcome: 1 - censor_event\n",
    "            self.data[\"censor_binary\"] = 1 - self.data[self.censor_event]\n",
    "\n",
    "            # Prepare independent (X) and dependent (y) variables\n",
    "            X = sm.add_constant(self.data[\"denom\"])\n",
    "            y = self.data[\"censor_binary\"]\n",
    "\n",
    "            # Choose model type\n",
    "            if model_type == \"logit\":\n",
    "                model = sm.Logit(y, X).fit(disp=0)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported model type. Only 'logit' is available for now.\")\n",
    "\n",
    "            # Save model\n",
    "            model.save(os.path.join(save_path, \"censor_model.pickle\"))\n",
    "\n",
    "            # Store results\n",
    "            self.censor_model = model\n",
    "            self.censor_weights = model.predict(X)\n",
    "            self.model_fitted = True\n",
    "\n",
    "            print(f\"Censor weights calculated and saved in {save_path}.\")\n",
    "\n",
    "    @property\n",
    "    def get_censor_weights(self):\n",
    "        \"\"\"Automatically calculate censor weights if not already done.\"\"\"\n",
    "        if not self.model_fitted:\n",
    "            print(\"Censor model not fitted yet. Automatically running `calculate_weights()`...\")\n",
    "            self.calculate_weights(\"trial_default\", weight_type=\"censor\")  # Default save path\n",
    "        return self.censor_weights\n",
    "\n",
    "# Example Usage\n",
    "trial_pp = Trial(data_censored)  # Initialize with dataset\n",
    "\n",
    "# Define censor weight model\n",
    "trial_pp.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\"\n",
    ")\n",
    "\n",
    "# Check message output (mimics R)\n",
    "print(trial_pp.get_censor_weights.head())  # Automatically runs `calculate_weights()` if needed\n",
    "\n",
    "# For ITT model (with pooling in numerator)\n",
    "trial_itt = Trial(data_censored)\n",
    "trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"numerator\"\n",
    ")\n",
    "\n",
    "print(trial_itt.get_censor_weights.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f84e1b-363e-4a6a-88f7-81383b194144",
   "metadata": {},
   "source": [
    "### **3.2 Other Transformative Sensoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700e7da-08e7-40d3-a9dd-e224ab08292a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
