{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12b26f5-8776-4c4a-a876-7726e1797e34",
   "metadata": {},
   "source": [
    "# **Target Trial Emulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a6341-9736-4412-8c58-eb38f9e41d08",
   "metadata": {},
   "source": [
    "### **Submitted by:**\n",
    "- **Ladrera**, Raiken\n",
    "- **Tibon**, Hestia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995110c-b937-411b-a74b-e549b35d8fc7",
   "metadata": {},
   "source": [
    "## **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8195ac-f9a9-4240-92a8-c3e7face5e4f",
   "metadata": {},
   "source": [
    "Assignment 1 for Clustering: New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "- Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "- Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "- Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "- Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "- Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "- Do this by pair, preferably your thesis partner.\n",
    "- Push to your github repository.\n",
    "\n",
    "HINT: For those who dont have a thesis topic yet, you can actually develop a thesis topic out of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52acd26-f363-4cbb-9f2b-ee78ed563c0e",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b290f6f-11b5-4dd2-9b01-eb2fd4a0d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created:\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_pp\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_itt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "estimand_pp = \"PP\"  # Per-protocol\n",
    "estimand_itt = \"ITT\"  # Intention-to-treat\n",
    "\n",
    "# Directories for saving outputs\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directories created:\\n{trial_pp_dir}\\n{trial_itt_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ddcb3-eb59-4048-a15f-c94650a8635e",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49319ec8-50dc-4ae8-972a-2ed1dd7381b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "   id  period  treatment  outcome  eligible  age  x1        x2  x3\n",
      "0   1       0          1        0         1   36   1  1.146148   0\n",
      "1   1       1          1        0         0   37   1  0.002200   0\n",
      "2   1       2          1        0         0   38   0 -0.481762   0\n",
      "3   1       3          1        0         0   39   0  0.007872   0\n",
      "4   1       4          1        0         0   40   1  0.216054   0\n",
      "   id  period  treatment  outcome  eligible  age  x1        x2  x3\n",
      "0   1       0          1        0         1   36   1  1.146148   0\n",
      "1   1       1          1        0         0   37   1  0.002200   0\n",
      "2   1       2          1        0         0   38   0 -0.481762   0\n",
      "3   1       3          1        0         0   39   0  0.007872   0\n",
      "4   1       4          1        0         0   40   1  0.216054   0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data_censored.csv\" \n",
    "data_censored = pd.read_csv(data_path)\n",
    "print(data_censored.head())\n",
    "\n",
    "columns_needed = [\"id\", \"period\", \"treatment\", \"outcome\", \"eligible\", \"age\", \"x1\", \"x2\", \"x3\"]\n",
    "trial_pp = data_censored[columns_needed].copy()\n",
    "trial_itt = data_censored[columns_needed].copy()\n",
    "\n",
    "print(trial_pp.head())\n",
    "print(trial_itt.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63db407-de57-453e-9059-5a20504b6efc",
   "metadata": {},
   "source": [
    "## **3. Weight Models and Censoring**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fb94b-141e-4b36-949f-5da96f54bebb",
   "metadata": {},
   "source": [
    "#### **3.1. Treatment and Switching Weight Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3564e260-a59c-45bd-ac8d-3eb6309a0050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: x2 perfectly predicts eligible, removing it.\n",
      "Warning: No valid covariates remain after filtering.\n",
      "Warning: x2 perfectly predicts eligible, removing it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 2 out of 2 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 4 out of 4 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 2 out of 2 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 4 out of 4 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 2 out of 2 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def check_perfect_separation(data, outcome_col, covariates):\n",
    "    \"\"\"Check for perfect separation and return filtered covariates.\"\"\"\n",
    "    valid_covariates = covariates.copy()\n",
    "    for col in covariates:\n",
    "        if data[col].nunique() <= 1 or data.groupby(col)[outcome_col].nunique().max() == 1:\n",
    "            print(f\"Warning: {col} perfectly predicts {outcome_col}, removing it.\")\n",
    "            valid_covariates.remove(col)\n",
    "    if not valid_covariates:\n",
    "        print(\"Warning: No valid covariates remain after filtering.\")\n",
    "    return valid_covariates\n",
    "\n",
    "\n",
    "def fit_logistic_model(data, outcome_col, covariates):\n",
    "    \"\"\"Fit a logistic regression model with increased solver accuracy.\"\"\"\n",
    "    if not covariates:\n",
    "        return np.full(len(data), 0.5)  # Default probability if no valid predictors\n",
    "    \n",
    "    X = sm.add_constant(data[covariates])\n",
    "    y = data[outcome_col]\n",
    "    try:\n",
    "        model = sm.Logit(y, X).fit_regularized(disp=0, alpha=1e-6, maxiter=500)\n",
    "        return np.clip(model.predict(X), 1e-6, 1 - 1e-6)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Logistic regression failed for {outcome_col}: {e}\")\n",
    "        return np.full(len(data), 0.5)\n",
    "\n",
    "\n",
    "def calculate_weights(data, treatment_col, numerator_covariates, denominator_covariates):\n",
    "    \"\"\"Calculate stabilized inverse probability of treatment weights (IPTW).\"\"\"\n",
    "    data = data.copy()\n",
    "    prev_treatment = data[treatment_col].shift(1)\n",
    "    \n",
    "    for prev_value in [0, 1]:\n",
    "        subset = data.loc[prev_treatment == prev_value].copy()\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        \n",
    "        num_cov = check_perfect_separation(subset, treatment_col, numerator_covariates.copy())\n",
    "        denom_cov = check_perfect_separation(subset, treatment_col, denominator_covariates.copy())\n",
    "        \n",
    "        data.loc[subset.index, f\"num_propensity_{prev_value}\"] = fit_logistic_model(subset, treatment_col, num_cov)\n",
    "        data.loc[subset.index, f\"denom_propensity_{prev_value}\"] = fit_logistic_model(subset, treatment_col, denom_cov)\n",
    "    \n",
    "    data[\"stabilized_weight\"] = (\n",
    "        data.filter(like=\"num_propensity_\").sum(axis=1) /\n",
    "        (data.filter(like=\"denom_propensity_\").sum(axis=1) + 1e-6)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def apply_ipcw(data, censor_col, numerator_covariates, denominator_covariates):\n",
    "    \"\"\"Apply inverse probability of censoring weights (IPCW).\"\"\"\n",
    "    data = data.copy()\n",
    "    num_cov = check_perfect_separation(data, censor_col, numerator_covariates.copy())\n",
    "    denom_cov = check_perfect_separation(data, censor_col, denominator_covariates.copy())\n",
    "    \n",
    "    data[\"num_censor_prob\"] = fit_logistic_model(data, censor_col, num_cov)\n",
    "    data[\"denom_censor_prob\"] = fit_logistic_model(data, censor_col, denom_cov)\n",
    "    \n",
    "    data[\"ipcw_weight\"] = (\n",
    "        data[\"num_censor_prob\"] / (data[\"denom_censor_prob\"] + 1e-6)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "# Example application\n",
    "numerator_covariates = [\"age\"]\n",
    "denominator_covariates = [\"age\", \"x1\", \"x3\"]\n",
    "trial_pp = calculate_weights(trial_pp, \"treatment\", numerator_covariates, denominator_covariates)\n",
    "\n",
    "numerator_censor_covariates = [\"x2\"]\n",
    "denominator_censor_covariates = [\"x2\", \"x1\"]\n",
    "trial_pp = apply_ipcw(trial_pp, \"eligible\", numerator_censor_covariates, denominator_censor_covariates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76d34915-fc06-495f-8af3-2df524493a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2\n",
      " 1.146148    1\n",
      "-1.162366    1\n",
      " 0.024422    1\n",
      "-1.711934    1\n",
      " 0.151505    1\n",
      "            ..\n",
      " 0.846777    1\n",
      "-0.980451    1\n",
      " 1.503913    1\n",
      " 0.231787    1\n",
      "-1.340497    1\n",
      "Name: count, Length: 725, dtype: int64\n",
      "x2\n",
      "-3.284355    1\n",
      "-2.789628    1\n",
      "-2.778994    1\n",
      "-2.716380    1\n",
      "-2.614978    1\n",
      "            ..\n",
      " 2.465086    1\n",
      " 2.831169    1\n",
      " 2.866680    1\n",
      " 3.321383    1\n",
      " 3.907648    1\n",
      "Name: eligible, Length: 725, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trial_pp[\"x2\"].value_counts())\n",
    "print(trial_pp.groupby(\"x2\")[\"eligible\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d711026-be70-4243-b021-987edcebc925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                x1        x2        x3       age  eligible\n",
      "x1        1.000000  0.072324 -0.034552  0.040720  0.060087\n",
      "x2        0.072324  1.000000 -0.067664  0.002637  0.074121\n",
      "x3       -0.034552 -0.067664  1.000000 -0.135130  0.079643\n",
      "age       0.040720  0.002637 -0.135130  1.000000 -0.319038\n",
      "eligible  0.060087  0.074121  0.079643 -0.319038  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(trial_pp[[\"x1\", \"x2\", \"x3\", \"age\", \"eligible\"]].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "177aab22-4cee-4371-8607-82c22283aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                      0\n",
      "period                  0\n",
      "treatment               0\n",
      "outcome                 0\n",
      "eligible                0\n",
      "age                     0\n",
      "x1                      0\n",
      "x2                      0\n",
      "x3                      0\n",
      "num_propensity_0      340\n",
      "denom_propensity_0    340\n",
      "num_propensity_1      386\n",
      "denom_propensity_1    386\n",
      "stabilized_weight       0\n",
      "num_censor_prob         0\n",
      "denom_censor_prob       0\n",
      "ipcw_weight             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trial_pp.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8932121-1a30-43cc-9cad-9777f9487f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
