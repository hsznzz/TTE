{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12b26f5-8776-4c4a-a876-7726e1797e34",
   "metadata": {},
   "source": [
    "# **Target Trial Emulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a6341-9736-4412-8c58-eb38f9e41d08",
   "metadata": {},
   "source": [
    "### **Submitted by:**\n",
    "- **Ladrera**, Raiken\n",
    "- **Tibon**, Hestia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995110c-b937-411b-a74b-e549b35d8fc7",
   "metadata": {},
   "source": [
    "## **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8195ac-f9a9-4240-92a8-c3e7face5e4f",
   "metadata": {},
   "source": [
    "Assignment 1 for Clustering: New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "- Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "- Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "- Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "- Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "- Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "- Do this by pair, preferably your thesis partner.\n",
    "- Push to your github repository.\n",
    "\n",
    "HINT: For those who dont have a thesis topic yet, you can actually develop a thesis topic out of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52acd26-f363-4cbb-9f2b-ee78ed563c0e",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b290f6f-11b5-4dd2-9b01-eb2fd4a0d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created:\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_pp\n",
      "C:\\Users\\meizi\\Documents\\GitHub\\TTE-v2\\trial_itt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the estimand variables\n",
    "estimand_pp = \"PP\"  # Per-protocol\n",
    "estimand_itt = \"ITT\"  # Intention-to-treat\n",
    "\n",
    "# Create directories for saving outputs\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directories created:\\n{trial_pp_dir}\\n{trial_itt_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ddcb3-eb59-4048-a15f-c94650a8635e",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49319ec8-50dc-4ae8-972a-2ed1dd7381b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "   id  period  treatment  outcome  eligible\n",
      "0   1       0          1        0         1\n",
      "1   1       1          1        0         0\n",
      "2   1       2          1        0         0\n",
      "3   1       3          1        0         0\n",
      "4   1       4          1        0         0\n",
      "   id  period  treatment  outcome  eligible\n",
      "0   1       0          1        0         1\n",
      "1   1       1          1        0         0\n",
      "2   1       2          1        0         0\n",
      "3   1       3          1        0         0\n",
      "4   1       4          1        0         0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = \"data_censored.csv\"  # Path to uploaded file\n",
    "data_censored = pd.read_csv(data_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(data_censored.head())\n",
    "\n",
    "# Select relevant columns for target trial emulation\n",
    "columns_needed = [\"id\", \"period\", \"treatment\", \"outcome\", \"eligible\"]\n",
    "trial_pp = data_censored[columns_needed].copy()\n",
    "trial_itt = data_censored[columns_needed].copy()\n",
    "\n",
    "# Display processed data\n",
    "print(trial_pp.head())\n",
    "print(trial_itt.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63db407-de57-453e-9059-5a20504b6efc",
   "metadata": {},
   "source": [
    "## **3. Weight Models and Censoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f11416-91e7-43ec-94c8-4649f8c6424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.630237\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meizi\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2441: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m\n\u001b[0;32m     52\u001b[0m trial_pp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcensored\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     59\u001b[0m })\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Fit switching weight models\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m switch_models \u001b[38;5;241m=\u001b[39m set_switch_weight_model(\n\u001b[0;32m     63\u001b[0m     data\u001b[38;5;241m=\u001b[39mtrial_pp,\n\u001b[0;32m     64\u001b[0m     numerator_formula\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatment ~ age\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     65\u001b[0m     denominator_formula\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatment ~ age + x1 + x3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     66\u001b[0m     save_path\u001b[38;5;241m=\u001b[39mtrial_pp_dir\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Fit censoring weight models\u001b[39;00m\n\u001b[0;32m     70\u001b[0m censor_models \u001b[38;5;241m=\u001b[39m set_censor_weight_model(\n\u001b[0;32m     71\u001b[0m     data\u001b[38;5;241m=\u001b[39mtrial_pp,\n\u001b[0;32m     72\u001b[0m     censor_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcensored\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     save_path\u001b[38;5;241m=\u001b[39mtrial_pp_dir\n\u001b[0;32m     77\u001b[0m )\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mset_switch_weight_model\u001b[1;34m(data, numerator_formula, denominator_formula, save_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m num_model \u001b[38;5;241m=\u001b[39m smf\u001b[38;5;241m.\u001b[39mlogit(numerator_formula, data\u001b[38;5;241m=\u001b[39mdata)\u001b[38;5;241m.\u001b[39mfit(maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)  \u001b[38;5;66;03m# Increased max iterations\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Fit denominator model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m denom_model \u001b[38;5;241m=\u001b[39m smf\u001b[38;5;241m.\u001b[39mlogit(denominator_formula, data\u001b[38;5;241m=\u001b[39mdata)\u001b[38;5;241m.\u001b[39mfit(maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)  \u001b[38;5;66;03m# Increased max iterations\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Save models\u001b[39;00m\n\u001b[0;32m     18\u001b[0m num_model\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumerator_model.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2599\u001b[0m, in \u001b[0;36mLogit.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   2596\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[0;32m   2597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[0;32m   2598\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2599\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(start_params\u001b[38;5;241m=\u001b[39mstart_params,\n\u001b[0;32m   2600\u001b[0m                           method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   2601\u001b[0m                           maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   2602\u001b[0m                           full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m   2603\u001b[0m                           disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m   2604\u001b[0m                           callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m   2605\u001b[0m                           \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2607\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[0;32m   2608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(start_params\u001b[38;5;241m=\u001b[39mstart_params,\n\u001b[0;32m    244\u001b[0m                      method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    245\u001b[0m                      maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    246\u001b[0m                      full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m    247\u001b[0m                      disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    248\u001b[0m                      callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    249\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[1;32m--> 582\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[38;5;241m-\u001b[39mretvals[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHessian\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m nobs\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[0;32m    584\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39minv(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import os\n",
    "\n",
    "# Create directory to store models if it doesn't exist\n",
    "trial_pp_dir = \"switch_models\"\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "# Function to set treatment switching weight models\n",
    "def set_switch_weight_model(data, numerator_formula, denominator_formula, save_path):\n",
    "    # Fit numerator model\n",
    "    num_model = smf.logit(numerator_formula, data=data).fit(maxiter=1000)  # Increased max iterations\n",
    "    \n",
    "    # Fit denominator model\n",
    "    denom_model = smf.logit(denominator_formula, data=data).fit(maxiter=1000)  # Increased max iterations\n",
    "    \n",
    "    # Save models\n",
    "    num_model.save(os.path.join(save_path, \"numerator_model.pickle\"))\n",
    "    denom_model.save(os.path.join(save_path, \"denominator_model.pickle\"))\n",
    "    \n",
    "    return {\"numerator_model\": num_model, \"denominator_model\": denom_model}\n",
    "\n",
    "# Function to set other informative censoring weight models\n",
    "def set_censor_weight_model(data, censor_event, numerator_formula, denominator_formula, pool_models, save_path):\n",
    "    data[\"censored\"] = data[censor_event]  # Define censoring column\n",
    "\n",
    "    # Fit numerator model\n",
    "    num_model = smf.logit(numerator_formula, data=data).fit(maxiter=1000)  # Increased max iterations\n",
    "    \n",
    "    # Fit denominator model\n",
    "    denom_model = smf.logit(denominator_formula, data=data).fit(maxiter=1000)  # Increased max iterations\n",
    "    \n",
    "    # Save models\n",
    "    num_model.save(os.path.join(save_path, \"censor_numerator_model.pickle\"))\n",
    "    denom_model.save(os.path.join(save_path, \"censor_denominator_model.pickle\"))\n",
    "    \n",
    "    return {\"numerator_model\": num_model, \"denominator_model\": denom_model}\n",
    "\n",
    "# Function to calculate weights (Inverse Probability Weights)\n",
    "def calculate_weights(data, models, weight_col=\"ipw\"):\n",
    "    num_preds = models[\"numerator_model\"].predict(data)\n",
    "    denom_preds = models[\"denominator_model\"].predict(data)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    denom_preds = denom_preds.replace(0, 1e-6)\n",
    "    \n",
    "    # Compute stabilized weights\n",
    "    data[weight_col] = num_preds / denom_preds\n",
    "    return data\n",
    "\n",
    "# Example DataFrame (replace this with your actual dataset)\n",
    "trial_pp = pd.DataFrame({\n",
    "    \"treatment\": [0, 1, 0, 1, 0],\n",
    "    \"age\": [25, 35, 45, 30, 40],\n",
    "    \"x1\": [1, 0, 1, 0, 1],\n",
    "    \"x3\": [0, 1, 0, 1, 0],\n",
    "    \"x2\": [0, 1, 1, 0, 1],\n",
    "    \"censored\": [0, 1, 0, 1, 0]\n",
    "})\n",
    "\n",
    "# Fit switching weight models\n",
    "switch_models = set_switch_weight_model(\n",
    "    data=trial_pp,\n",
    "    numerator_formula=\"treatment ~ age\",\n",
    "    denominator_formula=\"treatment ~ age + x1 + x3\",\n",
    "    save_path=trial_pp_dir\n",
    ")\n",
    "\n",
    "# Fit censoring weight models\n",
    "censor_models = set_censor_weight_model(\n",
    "    data=trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator_formula=\"censored ~ x2\",\n",
    "    denominator_formula=\"censored ~ x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=trial_pp_dir\n",
    ")\n",
    "\n",
    "# Calculate weights\n",
    "trial_pp = calculate_weights(trial_pp, switch_models, weight_col=\"switch_ipw\")\n",
    "trial_pp = calculate_weights(trial_pp, censor_models, weight_col=\"censor_ipw\")\n",
    "\n",
    "# Display results\n",
    "print(trial_pp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0da53-c1d4-40ac-8026-ef3b43d89ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
